{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 範例 : (Kaggle)房價預測\n",
    "***\n",
    "- 以下用房價預測資料, 觀察均值編碼的效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [教學目標]\n",
    "- 以下用房價預測資料, 觀察均值編碼的效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [範例重點]\n",
    "- 觀察標籤編碼與均值編碼, 在特徵數量 / 線性迴歸分數 / 線性迴歸時間上, 分別有什麼影響 (In[3], Out[3], In[4], Out[4]) \n",
    "\n",
    "使用線性回歸時，均值編碼可以在幾乎相同的時間內提高預測精準度。\n",
    "\n",
    "- 觀察標籤編碼與均值編碼, 在特徵數量 / 梯度提升樹分數 / 梯度提升樹時間上, 分別有什麼影響 (In[5], Out[5], In[6], Out[6]) \n",
    "\n",
    "使用均值編碼並不會相對提高太多梯度提升樹的預測精準度，時間也會被拉長"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig  ... ScreenPorch PoolArea PoolQC Fence  \\\n",
       "0         Lvl    AllPub    Inside  ...           0        0    NaN   NaN   \n",
       "1         Lvl    AllPub       FR2  ...           0        0    NaN   NaN   \n",
       "2         Lvl    AllPub    Inside  ...           0        0    NaN   NaN   \n",
       "3         Lvl    AllPub    Corner  ...           0        0    NaN   NaN   \n",
       "4         Lvl    AllPub       FR2  ...           0        0    NaN   NaN   \n",
       "\n",
       "  MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
       "0         NaN       0       2    2008        WD         Normal  \n",
       "1         NaN       0       5    2007        WD         Normal  \n",
       "2         NaN       0       9    2008        WD         Normal  \n",
       "3         NaN       0       2    2006        WD        Abnorml  \n",
       "4         NaN       0      12    2008        WD         Normal  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import copy,time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from  sklearn.model_selection import cross_val_score\n",
    "\n",
    "data_path = 'C:/Users/francis/Machine_Learning/francis/Documents/GitHub/4th-ML100Days/data/'\n",
    "df_train = pd.read_csv(data_path + 'house_train.csv.gz')\n",
    "df_test = pd.read_csv(data_path + 'house_test.csv.gz')\n",
    "df_train.head()\n",
    "Y_train = np.log1p(df_train['SalePrice'])\n",
    "ids = df_test['Id']\n",
    "df_train = df_train.drop(['Id','SalePrice'] , axis = 1)\n",
    "df_test = df_test.drop(['Id'] , axis = 1)\n",
    "df = pd.concat([df_train,df_test])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 Object Features : ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  MSZoning Street Alley LotShape LandContour Utilities LotConfig LandSlope  \\\n",
       "0       RL   Pave  None      Reg         Lvl    AllPub    Inside       Gtl   \n",
       "1       RL   Pave  None      Reg         Lvl    AllPub       FR2       Gtl   \n",
       "2       RL   Pave  None      IR1         Lvl    AllPub    Inside       Gtl   \n",
       "3       RL   Pave  None      IR1         Lvl    AllPub    Corner       Gtl   \n",
       "4       RL   Pave  None      IR1         Lvl    AllPub       FR2       Gtl   \n",
       "\n",
       "  Neighborhood Condition1  ... GarageType GarageFinish GarageQual GarageCond  \\\n",
       "0      CollgCr       Norm  ...     Attchd          RFn         TA         TA   \n",
       "1      Veenker      Feedr  ...     Attchd          RFn         TA         TA   \n",
       "2      CollgCr       Norm  ...     Attchd          RFn         TA         TA   \n",
       "3      Crawfor       Norm  ...     Detchd          Unf         TA         TA   \n",
       "4      NoRidge       Norm  ...     Attchd          RFn         TA         TA   \n",
       "\n",
       "  PavedDrive PoolQC Fence MiscFeature SaleType SaleCondition  \n",
       "0          Y   None  None        None       WD        Normal  \n",
       "1          Y   None  None        None       WD        Normal  \n",
       "2          Y   None  None        None       WD        Normal  \n",
       "3          Y   None  None        None       WD       Abnorml  \n",
       "4          Y   None  None        None       WD        Normal  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#只取類別值 (object) 型欄位, 存於 object_features 中\n",
    "object_features = []\n",
    "for dtype,feature in zip(df.dtypes,df.columns):\n",
    "    if dtype == 'object':\n",
    "        object_features.append(feature)\n",
    "print(f'{len(object_features)} Object Features : {object_features} \\n')\n",
    "# 只留類別型欄位\n",
    "df = df[object_features]\n",
    "df = df.fillna('None')\n",
    "train_num = Y_train.shape[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape : (1460, 43)\n",
      "score : 0.6615606866851304\n",
      "time : 0.08527469635009766 sec\n"
     ]
    }
   ],
   "source": [
    "# 對照組 : 標籤編碼 + 線性迴歸\n",
    "df_temp = pd.DataFrame()\n",
    "for col in df.columns:\n",
    "    df_temp[col] = LabelEncoder().fit_transform(df[col])\n",
    "X_train = df_temp[:train_num]\n",
    "estimator = LinearRegression()\n",
    "start = time.time()\n",
    "print(f'shape : {X_train.shape}')\n",
    "print(f'score : {cross_val_score(estimator,X_train,Y_train,cv = 5).mean()}')\n",
    "print(f'time : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape : (1460, 43)\n",
      "score : 0.7624230403716974\n",
      "time : 0.04986691474914551 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"'    \\nmean_df = data.groupby('Street')['SalePrice'].mean().reset_index()\\nmean_df.columns = ['Street' , 'Street_mean']\\ndata = pd.merge(data,mean_df,on = 'Street', how =  'left')\\ndata.drop(['Street'], axis = 1)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 均值編碼 + 線性迴歸\n",
    "data = pd.concat([df[:train_num],Y_train] , axis = 1)\n",
    "data\n",
    "#先將col內的類別所對應的SalePrice，用groupby統整，再將其對應的值做平均，算出col裡面不同類別的值對應的SalePrice值平均\n",
    "#做reset_index是為了不讓col的類別變成 index\n",
    "#使用pd.merge合併資料\n",
    "#on之所以會定為該column，是為了讓column_mean可以對應到相應的值，利用merge把column當作連接點，將兩個Data_Frame串接起來\n",
    "#how = left意思是只保留左邊的數據的對應值，ex:只取用data的column值，inner代表左右dataframe的交集，out代表聯集\n",
    "#最後再用drop將原本的物件column拿掉，column_mean取代column\n",
    "for col in df.columns:\n",
    "    mean_df = data.groupby(col)['SalePrice'].mean().reset_index()\n",
    "    mean_df.columns = [col,f'{col}_mean']\n",
    "    data = pd.merge(data , mean_df , how = 'left')\n",
    "    data = data.drop([col] , axis = 1)\n",
    "data = data.drop('SalePrice',axis = 1)\n",
    "estimator = LinearRegression()\n",
    "start = time.time()\n",
    "print(f'shape : {data.shape}')\n",
    "print(f'score : {cross_val_score(estimator,data,Y_train,cv = 5).mean()}')\n",
    "print(f'time : {time.time() - start} sec')\n",
    "''''''''''    \n",
    "mean_df = data.groupby('Street')['SalePrice'].mean().reset_index()\n",
    "mean_df.columns = ['Street' , 'Street_mean']\n",
    "data = pd.merge(data,mean_df,on = 'Street', how =  'left')\n",
    "data.drop(['Street'], axis = 1)\n",
    "'''''''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape : (1460, 43)\n",
      "score : 0.7773323844950724\n",
      "time : 1.288538932800293 sec\n"
     ]
    }
   ],
   "source": [
    "# 對照組 : 標籤編碼 + 梯度提升樹\n",
    "df_temp = pd.DataFrame()\n",
    "for col in df.columns:\n",
    "    df_temp[col] = LabelEncoder().fit_transform(df[col])\n",
    "X_train = df_temp[:train_num]\n",
    "estimator_1 = GradientBoostingRegressor()\n",
    "start = time.time()\n",
    "print(f'shape : {X_train.shape}')\n",
    "print(f'score : {cross_val_score(estimator_1,X_train,Y_train,cv = 5).mean()}')\n",
    "print(f'time : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape : (1460, 43)\n",
      "score : 0.8066034054503731\n",
      "time : 0.9289708137512207\n"
     ]
    }
   ],
   "source": [
    "# 均值編碼 + 梯度提升樹\n",
    "data = pd.concat([df[:train_num],Y_train],axis = 1)\n",
    "for col in df.columns:\n",
    "    mean_df = data.groupby(col)['SalePrice'].mean().reset_index()\n",
    "    mean_df.columns = [col,f'{col}_mean']\n",
    "    data = pd.merge(data,mean_df,on = col , how = 'left')\n",
    "    data = data.drop([col],axis = 1)\n",
    "data = data.drop(['SalePrice'] ,axis = 1)\n",
    "estimator_1 = GradientBoostingRegressor()\n",
    "start = time.time()\n",
    "print(f'shape : {data.shape}')\n",
    "print(f'score : {cross_val_score(estimator_1,data,Y_train,cv = 5).mean()}')\n",
    "print(f'time : {time.time() - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業1\n",
    "* 請仿照範例，將鐵達尼範例中的類別型特徵改用均值編碼實作一次\n",
    "\n",
    "# 作業2\n",
    "* 觀察鐵達尼生存預測中，均值編碼與標籤編碼兩者比較，哪一個效果比較好? 可能的原因是什麼?\n",
    "\n",
    "用均值編碼的效果，我認為是因為有些物件的特徵類別並沒有順序之分，一旦將其轉為從0到後面的數字，會影響預測的準確度，而均值編碼本身是根據其對應Y值的平均算出，所以值會跟Y值有正向的關係。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass                                               Name     Sex   Age  \\\n",
       "0       3                            Braund, Mr. Owen Harris    male  22.0   \n",
       "1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "2       3                             Heikkinen, Miss. Laina  female  26.0   \n",
       "3       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "4       3                           Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "   SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1      1      0          PC 17599  71.2833   C85        C  \n",
       "2      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      1      0            113803  53.1000  C123        S  \n",
       "4      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import copy,time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "df_train = pd.read_csv(data_path + 'titanic_train.csv')\n",
    "df_test = pd.read_csv(data_path + 'titanic_test.csv')\n",
    "df_train.head()\n",
    "Y_train = df_train['Survived']\n",
    "ids = df_test['PassengerId']\n",
    "df_train = df_train.drop(['PassengerId','Survived'], axis = 1)\n",
    "df_test = df_test.drop(['PassengerId'], axis = 1)\n",
    "df = pd.concat([df_train,df_test] ,axis = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Object Features : ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_features_1 = []\n",
    "for dtype,feature in zip(df.dtypes,df.columns):\n",
    "    if dtype == 'object':\n",
    "        object_features_1.append(feature)\n",
    "print(f'{len(object_features_1)} Object Features : {object_features_1} \\n')\n",
    "\n",
    "df = df[object_features_1]\n",
    "train_num = Y_train.shape[0]\n",
    "df = df.fillna('None')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape : (891, 5)\n",
      "score : 0.33494273995838764\n",
      "time : 0.0608372688293457 sec\n"
     ]
    }
   ],
   "source": [
    "# 對照組 : 標籤編碼 + 線性迴歸\n",
    "df_temp = pd.DataFrame()\n",
    "for col in df.columns:\n",
    "    df_temp[col] = LabelEncoder().fit_transform(df[col])\n",
    "X_train = df_temp[:train_num]\n",
    "estimator = LinearRegression()\n",
    "start = time.time()\n",
    "print(f'shape : {X_train.shape}')\n",
    "print(f'score : {cross_val_score(estimator,X_train,Y_train,cv = 5).mean()}')\n",
    "print(f'time : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape : (891, 6)\n",
      "score : 1.0\n",
      "time : 0.031913042068481445 sec\n"
     ]
    }
   ],
   "source": [
    "# 均值編碼 + 線性迴歸\n",
    "data = pd.concat([df[:train_num],Y_train] ,axis = 1)\n",
    "data.head()\n",
    "for col in df.columns:\n",
    "    mean_df = data.groupby(col)['Survived'].mean().reset_index()\n",
    "    mean_df.columns = [col,f'{col}_mean']\n",
    "    data = pd.merge(data,mean_df,on = col , how = 'left')\n",
    "    data = data.drop([col], axis = 1)\n",
    "data.head()\n",
    "data.drop(['Survived'], axis = 1)\n",
    "estimator = LinearRegression()\n",
    "start = time.time()\n",
    "print(f'shape : {data.shape}')\n",
    "print(f'score : {cross_val_score(estimator,data,Y_train,cv = 5).mean()}')\n",
    "print(f'time : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape : (891, 5)\n",
      "score : 0.37627110418594\n",
      "time : 0.2403576374053955 sec\n"
     ]
    }
   ],
   "source": [
    "# 對照組 : 標籤編碼 + 梯度提升樹\n",
    "df_temp = pd.DataFrame()\n",
    "for col in df.columns:\n",
    "    df_temp[col] = LabelEncoder().fit_transform(df[col])\n",
    "X_train = df_temp[:train_num]\n",
    "estimator_1 = GradientBoostingRegressor()\n",
    "start = time.time()\n",
    "print(f'shape : {X_train.shape}')\n",
    "print(f'score : {cross_val_score(estimator_1,X_train,Y_train,cv = 5).mean()}')\n",
    "print(f'time : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape : (891, 5)\n",
      "score : 0.9999996032710972\n",
      "time : 0.11868071556091309\n"
     ]
    }
   ],
   "source": [
    "# 均值編碼 + 梯度提升樹\n",
    "data = pd.concat([df[:train_num],Y_train], axis = 1)\n",
    "for col in df.columns:\n",
    "    mean_df = data.groupby(col)['Survived'].mean().reset_index()\n",
    "    mean_df.columns = [col,f'{col}_mean']\n",
    "    data = pd.merge(data,mean_df,on = col ,how = 'left')\n",
    "    data = data.drop([col],axis = 1)\n",
    "data = data.drop(['Survived'], axis = 1)\n",
    "start = time.time()\n",
    "print(f'shape : {data.shape}')\n",
    "print(f'score : {cross_val_score(estimator_1,data,Y_train,cv  = 5).mean()}')\n",
    "print(f'time : {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the words you want to say!:to be with you 100 days I Love You bae\n",
      "                o to to t           to to to                \n",
      "            o to to to to to    to to to to to to           \n",
      "          to to to to to to to to to to to to to to         \n",
      "         to to to to to to to to to to to to to to t        \n",
      "        to to to to to to to to to to to to to to to        \n",
      "        o to to to to to to to to to to to to to to t       \n",
      "         to to to to to to to to to to to to to to to       \n",
      "        to to to to to to to to to to to to to to to        \n",
      "        o to to to to to to to to to to to to to to t       \n",
      "         to to to to to to to to to to to to to to to       \n",
      "         o to to to to to to to to to to to to to to        \n",
      "          to to to to to to to to to to to to to to         \n",
      "          o to to to to to to to to to to to to to          \n",
      "            o to to to to to to to to to to to to           \n",
      "             to to to to to to to to to to to to            \n",
      "               to to to to to to to to to to to             \n",
      "                 to to to to to to to to to t               \n",
      "                   to to to to to to to to                  \n",
      "                     to to to to to to to                   \n",
      "                       to to to to to                       \n",
      "                          o to to t                         \n",
      "                              to                            \n",
      "                              o                             \n",
      "                                                            \n",
      "                e be be b           be be be                \n",
      "            e be be be be be    be be be be be be           \n",
      "          be be be be be be be be be be be be be be         \n",
      "         be be be be be be be be be be be be be be b        \n",
      "        be be be be be be be be be be be be be be be        \n",
      "        e be be be be be be be be be be be be be be b       \n",
      "         be be be be be be be be be be be be be be be       \n",
      "        be be be be be be be be be be be be be be be        \n",
      "        e be be be be be be be be be be be be be be b       \n",
      "         be be be be be be be be be be be be be be be       \n",
      "         e be be be be be be be be be be be be be be        \n",
      "          be be be be be be be be be be be be be be         \n",
      "          e be be be be be be be be be be be be be          \n",
      "            e be be be be be be be be be be be be           \n",
      "             be be be be be be be be be be be be            \n",
      "               be be be be be be be be be be be             \n",
      "                 be be be be be be be be be b               \n",
      "                   be be be be be be be be                  \n",
      "                     be be be be be be be                   \n",
      "                       be be be be be                       \n",
      "                          e be be b                         \n",
      "                              be                            \n",
      "                              e                             \n",
      "                                                            \n",
      "                 with wit            with wit               \n",
      "            ith with with wit   ith with with wit           \n",
      "          with with with with with with with with w         \n",
      "         with with with with with with with with wit        \n",
      "        with with with with with with with with with        \n",
      "        ith with with with with with with with with w       \n",
      "        th with with with with with with with with wi       \n",
      "        h with with with with with with with with wit       \n",
      "         with with with with with with with with with       \n",
      "        with with with with with with with with with        \n",
      "         th with with with with with with with with         \n",
      "           with with with with with with with with          \n",
      "          with with with with with with with with w         \n",
      "            h with with with with with with with            \n",
      "             with with with with with with with             \n",
      "              th with with with with with with              \n",
      "                with with with with with with               \n",
      "                  h with with with with wit                 \n",
      "                    ith with with with wi                   \n",
      "                       with with with                       \n",
      "                           with wit                         \n",
      "                             h w                            \n",
      "                              w                             \n",
      "                                                            \n",
      "                u you you           u you you               \n",
      "             you you you you     you you you you            \n",
      "          u you you you you you you you you you you         \n",
      "         u you you you you you you you you you you y        \n",
      "        u you you you you you you you you you you you       \n",
      "         you you you you you you you you you you you        \n",
      "        you you you you you you you you you you you y       \n",
      "        ou you you you you you you you you you you yo       \n",
      "        u you you you you you you you you you you you       \n",
      "         you you you you you you you you you you you        \n",
      "         ou you you you you you you you you you you         \n",
      "           you you you you you you you you you you          \n",
      "          you you you you you you you you you you y         \n",
      "             you you you you you you you you you            \n",
      "             ou you you you you you you you you             \n",
      "               you you you you you you you you              \n",
      "                u you you you you you you you               \n",
      "                  ou you you you you you yo                 \n",
      "                    you you you you you y                   \n",
      "                       you you you you                      \n",
      "                          you you y                         \n",
      "                             you                            \n",
      "                              u                             \n",
      "                                                            \n",
      "                0 100 100           0 100 100               \n",
      "             100 100 100 100     100 100 100 100            \n",
      "          0 100 100 100 100 100 100 100 100 100 100         \n",
      "         0 100 100 100 100 100 100 100 100 100 100 1        \n",
      "        0 100 100 100 100 100 100 100 100 100 100 100       \n",
      "         100 100 100 100 100 100 100 100 100 100 100        \n",
      "        100 100 100 100 100 100 100 100 100 100 100 1       \n",
      "        00 100 100 100 100 100 100 100 100 100 100 10       \n",
      "        0 100 100 100 100 100 100 100 100 100 100 100       \n",
      "         100 100 100 100 100 100 100 100 100 100 100        \n",
      "         00 100 100 100 100 100 100 100 100 100 100         \n",
      "           100 100 100 100 100 100 100 100 100 100          \n",
      "          100 100 100 100 100 100 100 100 100 100 1         \n",
      "             100 100 100 100 100 100 100 100 100            \n",
      "             00 100 100 100 100 100 100 100 100             \n",
      "               100 100 100 100 100 100 100 100              \n",
      "                0 100 100 100 100 100 100 100               \n",
      "                  00 100 100 100 100 100 10                 \n",
      "                    100 100 100 100 100 1                   \n",
      "                       100 100 100 100                      \n",
      "                          100 100 1                         \n",
      "                             100                            \n",
      "                              0                             \n",
      "                                                            \n",
      "                 days day            days day               \n",
      "            ays days days day   ays days days day           \n",
      "          days days days days days days days days d         \n",
      "         days days days days days days days days day        \n",
      "        days days days days days days days days days        \n",
      "        ays days days days days days days days days d       \n",
      "        ys days days days days days days days days da       \n",
      "        s days days days days days days days days day       \n",
      "         days days days days days days days days days       \n",
      "        days days days days days days days days days        \n",
      "         ys days days days days days days days days         \n",
      "           days days days days days days days days          \n",
      "          days days days days days days days days d         \n",
      "            s days days days days days days days            \n",
      "             days days days days days days days             \n",
      "              ys days days days days days days              \n",
      "                days days days days days days               \n",
      "                  s days days days days day                 \n",
      "                    ays days days days da                   \n",
      "                       days days days                       \n",
      "                           days day                         \n",
      "                             s d                            \n",
      "                              d                             \n",
      "                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                I I I I I           I I I I I               \n",
      "             I I I I I I I I     I I I I I I I I            \n",
      "          I I I I I I I I I I I I I I I I I I I I I         \n",
      "         I I I I I I I I I I I I I I I I I I I I I I        \n",
      "        I I I I I I I I I I I I I I I I I I I I I I I       \n",
      "         I I I I I I I I I I I I I I I I I I I I I I        \n",
      "        I I I I I I I I I I I I I I I I I I I I I I I       \n",
      "         I I I I I I I I I I I I I I I I I I I I I I        \n",
      "        I I I I I I I I I I I I I I I I I I I I I I I       \n",
      "         I I I I I I I I I I I I I I I I I I I I I I        \n",
      "          I I I I I I I I I I I I I I I I I I I I I         \n",
      "           I I I I I I I I I I I I I I I I I I I I          \n",
      "          I I I I I I I I I I I I I I I I I I I I I         \n",
      "             I I I I I I I I I I I I I I I I I I            \n",
      "              I I I I I I I I I I I I I I I I I             \n",
      "               I I I I I I I I I I I I I I I I              \n",
      "                I I I I I I I I I I I I I I I               \n",
      "                   I I I I I I I I I I I I                  \n",
      "                    I I I I I I I I I I I                   \n",
      "                       I I I I I I I I                      \n",
      "                          I I I I I                         \n",
      "                             I I                            \n",
      "                              I                             \n",
      "                                                            \n",
      "                 Love Lov            Love Lov               \n",
      "            ove Love Love Lov   ove Love Love Lov           \n",
      "          Love Love Love Love Love Love Love Love L         \n",
      "         Love Love Love Love Love Love Love Love Lov        \n",
      "        Love Love Love Love Love Love Love Love Love        \n",
      "        ove Love Love Love Love Love Love Love Love L       \n",
      "        ve Love Love Love Love Love Love Love Love Lo       \n",
      "        e Love Love Love Love Love Love Love Love Lov       \n",
      "         Love Love Love Love Love Love Love Love Love       \n",
      "        Love Love Love Love Love Love Love Love Love        \n",
      "         ve Love Love Love Love Love Love Love Love         \n",
      "           Love Love Love Love Love Love Love Love          \n",
      "          Love Love Love Love Love Love Love Love L         \n",
      "            e Love Love Love Love Love Love Love            \n",
      "             Love Love Love Love Love Love Love             \n",
      "              ve Love Love Love Love Love Love              \n",
      "                Love Love Love Love Love Love               \n",
      "                  e Love Love Love Love Lov                 \n",
      "                    ove Love Love Love Lo                   \n",
      "                       Love Love Love                       \n",
      "                           Love Lov                         \n",
      "                             e L                            \n",
      "                              L                             \n",
      "                                                            \n",
      "                u You You           u You You               \n",
      "             You You You You     You You You You            \n",
      "          u You You You You You You You You You You         \n",
      "         u You You You You You You You You You You Y        \n",
      "        u You You You You You You You You You You You       \n",
      "         You You You You You You You You You You You        \n",
      "        You You You You You You You You You You You Y       \n",
      "        ou You You You You You You You You You You Yo       \n",
      "        u You You You You You You You You You You You       \n",
      "         You You You You You You You You You You You        \n",
      "         ou You You You You You You You You You You         \n",
      "           You You You You You You You You You You          \n",
      "          You You You You You You You You You You Y         \n",
      "             You You You You You You You You You            \n",
      "             ou You You You You You You You You             \n",
      "               You You You You You You You You              \n",
      "                u You You You You You You You               \n",
      "                  ou You You You You You Yo                 \n",
      "                    You You You You You Y                   \n",
      "                       You You You You                      \n",
      "                          You You Y                         \n",
      "                             You                            \n",
      "                              u                             \n",
      "                                                            \n",
      "                e bae bae           e bae bae               \n",
      "             bae bae bae bae     bae bae bae bae            \n",
      "          e bae bae bae bae bae bae bae bae bae bae         \n",
      "         e bae bae bae bae bae bae bae bae bae bae b        \n",
      "        e bae bae bae bae bae bae bae bae bae bae bae       \n",
      "         bae bae bae bae bae bae bae bae bae bae bae        \n",
      "        bae bae bae bae bae bae bae bae bae bae bae b       \n",
      "        ae bae bae bae bae bae bae bae bae bae bae ba       \n",
      "        e bae bae bae bae bae bae bae bae bae bae bae       \n",
      "         bae bae bae bae bae bae bae bae bae bae bae        \n",
      "         ae bae bae bae bae bae bae bae bae bae bae         \n",
      "           bae bae bae bae bae bae bae bae bae bae          \n",
      "          bae bae bae bae bae bae bae bae bae bae b         \n",
      "             bae bae bae bae bae bae bae bae bae            \n",
      "             ae bae bae bae bae bae bae bae bae             \n",
      "               bae bae bae bae bae bae bae bae              \n",
      "                e bae bae bae bae bae bae bae               \n",
      "                  ae bae bae bae bae bae ba                 \n",
      "                    bae bae bae bae bae b                   \n",
      "                       bae bae bae bae                      \n",
      "                          bae bae b                         \n",
      "                             bae                            \n",
      "                              e                             \n",
      "                                                            \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "words = input('Please input the words you want to say!:')\n",
    "for item in words.split():\n",
    "    item = item + ' '\n",
    "    letterlist = []\n",
    "    for y in range(12, -12, -1):\n",
    "        list_X = []\n",
    "        letters = ''\n",
    "        for x in range(-30, 30):\n",
    "            expression = ((x*0.05)**2+(y*0.1)**2-1)**3-(x*0.05)**2*(y*0.1)**3\n",
    "            if expression <= 0:\n",
    "                letters += item[(x-y) % len(item)]\n",
    "            else:\n",
    "                letters += ' '\n",
    "        list_X.append(letters)\n",
    "        letterlist += list_X\n",
    "    print('\\n'.join(letterlist))\n",
    "    time.sleep(1.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
